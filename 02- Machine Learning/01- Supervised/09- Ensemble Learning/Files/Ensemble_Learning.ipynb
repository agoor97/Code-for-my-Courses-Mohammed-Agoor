{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33578e46",
   "metadata": {
    "id": "33578e46"
   },
   "outputs": [],
   "source": [
    "## Main Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "## To draw DT\n",
    "from six import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "## Embeded Datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "## For shuffling the Dataset\n",
    "from sklearn import utils\n",
    "\n",
    "## Metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "## Algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Ensemble Models (There is for Classification and Regression)\n",
    "from sklearn.ensemble import VotingClassifier, VotingRegressor                          ## One for each task\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor                        ## One for each task\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor              ## one for each task\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor                      ## one for each task\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor      ## one for each task\n",
    "\n",
    "\n",
    "## XGBoost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bf15ba",
   "metadata": {
    "id": "89bf15ba"
   },
   "source": [
    "## `Classification`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0abfb",
   "metadata": {
    "id": "3ff0abfb"
   },
   "source": [
    "### `Loading the iris Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58a776a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d58a776a",
    "outputId": "35e87d9c-adee-4e5d-8d5a-f622c658f698"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the iris dataset from the embeded datasets provided in sklearn\n",
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "## check the dataset by checking its keys\n",
    "iris_dataset.keys()           ## each key has data or information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1db9514",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "b1db9514",
    "outputId": "c16442ea-6928-4cb0-8c4d-b253cf0ebf69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's get all together and create a DF\n",
    "## I will do it in very fast way and it is my preferable one, but there are many ways as we learned together \n",
    "\n",
    "df_iris = pd.DataFrame(np.c_[iris_dataset['data'], iris_dataset['target'].reshape(-1, 1)], \n",
    "                       columns=iris_dataset['feature_names']+['target'])\n",
    "\n",
    "## check the head\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0065164",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "f0065164",
    "outputId": "b816f9d9-aa98-40fa-a9a2-533e069b46e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "73                 6.1               2.8                4.7               1.2   \n",
       "18                 5.7               3.8                1.7               0.3   \n",
       "118                7.7               2.6                6.9               2.3   \n",
       "78                 6.0               2.9                4.5               1.5   \n",
       "76                 6.8               2.8                4.8               1.4   \n",
       "\n",
       "     target  \n",
       "73      1.0  \n",
       "18      0.0  \n",
       "118     2.0  \n",
       "78      1.0  \n",
       "76      1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's shuffle the Dataset as you see that the target is ordered (0 then 1 then 2) --> Classification problem\n",
    "## You can use function (sample) provided in pandas or use (shuffle) in sklearn\n",
    "df_iris = utils.shuffle(df_iris, random_state=42)   ## shuffle and overwrite\n",
    "\n",
    "## check the head again\n",
    "df_iris.head()    ## OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3b7439",
   "metadata": {
    "id": "ee3b7439"
   },
   "source": [
    "### `Exploratory Data Analysis (EDA)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d37fe8",
   "metadata": {
    "id": "61d37fe8"
   },
   "outputs": [],
   "source": [
    "## Do it Yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee044c67",
   "metadata": {
    "id": "ee044c67"
   },
   "source": [
    "### `Preprocessing`\n",
    "`The Dataset is very small, It is a Toy example, I will not split the data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb6f211",
   "metadata": {
    "id": "6cb6f211"
   },
   "outputs": [],
   "source": [
    "### Split the Dataset to Features and Target\n",
    "X = df_iris.drop(columns=['target'], axis=1)\n",
    "y = df_iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b00342c",
   "metadata": {
    "id": "8b00342c"
   },
   "outputs": [],
   "source": [
    "## Let's impute (although there is no nulls) and standardize the Dataset ---> All in Pipeline\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "                              ]\n",
    "                       )\n",
    "\n",
    "X_train = num_pipeline.fit_transform(X)\n",
    "y_train = y.copy()   ## doesn't matter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbe9a6",
   "metadata": {
    "id": "f0cbe9a6"
   },
   "source": [
    "### `Building a ML Model`\n",
    "* `Evaluation Metric is Accuracy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca2cee2",
   "metadata": {},
   "source": [
    "### `1. Logistic Regression` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26d6f642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "logit_clf = LogisticRegression(C=0.1)\n",
    "logit_clf.fit(X_train, y_train)  ## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea6ac4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Mean) scores using \"Logistic Regression\" -- 0.913\n"
     ]
    }
   ],
   "source": [
    "## Using cross validation for prediction and evaluation\n",
    "acc_scores_logit = cross_val_score(estimator=logit_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "print(f'Accuracy (Mean) scores using \"Logistic Regression\" -- {acc_scores_logit.mean():.3f}', )\n",
    "\n",
    "## Prediction using cross validation\n",
    "y_pred_logit = cross_val_predict(estimator=logit_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77c1b9",
   "metadata": {},
   "source": [
    "### `2. KNN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b376ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using KNN\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)  ## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e4354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Mean) scores using \"KNN\" -- 0.947\n"
     ]
    }
   ],
   "source": [
    "## Using cross validation for prediction and evaluation\n",
    "acc_scores_knn = cross_val_score(estimator=knn_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "print(f'Accuracy (Mean) scores using \"KNN\" -- {acc_scores_knn.mean():.3f}', )\n",
    "\n",
    "## Prediction using cross validation\n",
    "y_pred_knn = cross_val_predict(estimator=knn_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f41939",
   "metadata": {},
   "source": [
    "### `3. SVC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f88649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear', probability=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using SVMs\n",
    "svm_clf = SVC(kernel='linear', C=0.1, probability=True)\n",
    "svm_clf.fit(X_train, y_train)  ## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06cf528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Mean) scores using \"SVM\" -- 0.947\n"
     ]
    }
   ],
   "source": [
    "## Using cross validation for prediction and evaluation\n",
    "acc_scores_svm = cross_val_score(estimator=svm_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "print(f'Accuracy (Mean) scores using \"SVM\" -- {acc_scores_svm.mean():.3f}', )\n",
    "\n",
    "## Prediction using cross validation\n",
    "y_pred_svm = cross_val_predict(estimator=svm_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2cb43b",
   "metadata": {},
   "source": [
    "### `Decision Trees`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46ff6a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Decison Trees\n",
    "tree_clf = DecisionTreeClassifier(criterion='gini', max_depth=2)\n",
    "tree_clf.fit(X_train, y_train)  ## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9659d818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Mean) scores using \"Decision Trees\" -- 0.927\n"
     ]
    }
   ],
   "source": [
    "## Using cross validation for prediction and evaluation\n",
    "acc_scores_tree = cross_val_score(estimator=tree_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "print(f'Accuracy (Mean) scores using \"Decision Trees\" -- {acc_scores_tree.mean():.3f}', )\n",
    "\n",
    "## Prediction using cross validation\n",
    "y_pred_tree = cross_val_predict(estimator=tree_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13770de9",
   "metadata": {},
   "source": [
    "> * `Enough, Let's vote all the above models`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b0352",
   "metadata": {},
   "source": [
    "### `Voting Classifiers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fda4d069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logit', LogisticRegression(C=0.1)),\n",
       "                             ('knn', KNeighborsClassifier()),\n",
       "                             ('svm',\n",
       "                              SVC(C=0.1, kernel='linear', probability=True)),\n",
       "                             ('tree', DecisionTreeClassifier(max_depth=2))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Voting the above 4 models, firstly --------> try tuning the above models before voting\n",
    "voting_clf = VotingClassifier(estimators=\n",
    "                                    [\n",
    "                                        ('logit', logit_clf),\n",
    "                                        ('knn', knn_clf),\n",
    "                                        ('svm', svm_clf),\n",
    "                                        ('tree', tree_clf)\n",
    "                                    ], \n",
    "                              voting='hard'      ## --> Try using (hard), take your time playing with code.\n",
    "                            )\n",
    "## deal with the (voting_clf) as an ordinary model                \n",
    "voting_clf.fit(X_train, y_train)  ## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a69e0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Mean) scores using \"Voting Classifier\" -- 0.960\n"
     ]
    }
   ],
   "source": [
    "## Using cross validation for prediction and evaluation\n",
    "acc_scores_voting = cross_val_score(estimator=voting_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "print(f'Accuracy (Mean) scores using \"Voting Classifier\" -- {acc_scores_voting.mean():.3f}', )\n",
    "\n",
    "## Prediction using cross validation\n",
    "y_pred_voting = cross_val_predict(estimator=voting_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, method='predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0be50de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression ------- Accuracy score is : 0.9133\n",
      "KNeighborsClassifier ------- Accuracy score is : 0.9467\n",
      "SVC ------- Accuracy score is : 0.9467\n",
      "DecisionTreeClassifier ------- Accuracy score is : 0.9333\n",
      "VotingClassifier ------- Accuracy score is : 0.9600\n"
     ]
    }
   ],
   "source": [
    "## Getting all together \n",
    "models_outs = {logit_clf:y_pred_logit, \n",
    "               knn_clf:y_pred_knn, \n",
    "               svm_clf:y_pred_svm, \n",
    "               tree_clf:y_pred_tree, \n",
    "               voting_clf:y_pred_voting}\n",
    "\n",
    "for idx, clf in enumerate(models_outs.keys()):\n",
    "    y_pred_each_clf = [*models_outs.values()][idx]   ## prediction for each model\n",
    "    acc_score = accuracy_score(y_train, y_pred_each_clf)   ## accuracy\n",
    "    print(clf.__class__.__name__, '-------', f'Accuracy score is : {acc_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecaf778",
   "metadata": {},
   "source": [
    "### `Bagging & Pasting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a024048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
       "                  max_samples=0.8, n_estimators=100, n_jobs=-1, oob_score=True,\n",
       "                  random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bagging and pasting for Decision Trees  ---> take your time discovering the hyperparameters\n",
    "## (max_samples) & (max_features) --> when (float) it will be a ratio from samples and features \n",
    "## (max_samples) & (max_features) --> when (int) the number taken from samples and features \n",
    "## (bootstrap_features) is working the same as (bootstrap) working but for features, (bootstrap) for samples.. --> take care\n",
    "bag_clf = BaggingClassifier(\n",
    "                  base_estimator=DecisionTreeClassifier(max_depth=2, criterion='gini'),    ## the base model itself\n",
    "                  n_estimators=100,                       ## Number of predictors (imortant Hyperparam)\n",
    "                  max_samples=0.8, max_features=1.0,     \n",
    "                  bootstrap=True,                         ## True --> Bagging & False --> Pasting\n",
    "                  oob_score=True,                         ## If you want to evaluate on oob set\n",
    "                  random_state=42, n_jobs=-1              ## Additional params\n",
    "                          )             \n",
    "\n",
    "bag_clf.fit(X_train, y_train)  ## train and deal with it as an ordinary model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ba47702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Mean) scores using \"Bagging of DT\" -- 0.940\n",
      "Evaluation of Out-of-Bag set is --  0.94\n"
     ]
    }
   ],
   "source": [
    "## Using cross validation for prediction and evaluation\n",
    "acc_scores_bagTree = cross_val_score(estimator=bag_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "print(f'Accuracy (Mean) scores using \"Bagging of DT\" -- {acc_scores_bagTree.mean():.3f}', )\n",
    "\n",
    "## oob now will be an attribute in the model as we set to True in the model\n",
    "## oob score gives an indication about the final score on test set, as model doesn't touch them while training.\n",
    "print('Evaluation of Out-of-Bag set is -- ', bag_clf.oob_score_)\n",
    "\n",
    "## Prediction using cross validation\n",
    "y_pred_bagTree = cross_val_predict(estimator=bag_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76223a59",
   "metadata": {},
   "source": [
    "### `RandomForest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "152c2719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, max_features=1.0, max_leaf_nodes=20,\n",
       "                       max_samples=0.8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## One of the most powerfull ML models avilable today, RandomForest (all is random)\n",
    "## Instead of building number of DT using Bagging, sklearn implemented RandomForest Model and it is very optimized\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, max_depth=3, max_leaf_nodes=20, \n",
    "                                    criterion='gini', max_features=1.0, max_samples=0.8)\n",
    "forest_clf.fit(X_train, y_train)  ## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5823e1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Mean) scores using \"RandomForest\" -- 0.960\n"
     ]
    }
   ],
   "source": [
    "## Using cross validation for prediction and evaluation\n",
    "acc_scores_forest = cross_val_score(estimator=forest_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "print(f'Accuracy (Mean) scores using \"RandomForest\" -- {acc_scores_forest.mean():.3f}', )\n",
    "\n",
    "## Prediction using cross validation\n",
    "y_pred_forest = cross_val_predict(estimator=forest_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef1026",
   "metadata": {},
   "source": [
    "``` python\n",
    "    ## The above RandomForest Model is equal to the following Bagging\n",
    "    equal_forest = BaggingClassifier( \n",
    "                                    base_estimator=DecisionTreeClassifier(max_depth=3, \n",
    "                                                                          splitter='random',   ## random split\n",
    "                                                                          criterion='gini', \n",
    "                                                                          max_leaf_nodes=20), \n",
    "                                    n_estimators=100,\n",
    "                                    max_features=1.0, \n",
    "                                    max_samples=0.8\n",
    "                                    )\n",
    "\n",
    "    ## Instead of using this technique --> we always use RandomForest provided in sklearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe29fb9",
   "metadata": {},
   "source": [
    "### `Feature Importance using RF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac56f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the Features Importance (they are normalized in RF, sum=1)\n",
    "feat_dict = {}      ## to append in it\n",
    "for name, score in zip(iris_dataset['feature_names'], forest_clf.feature_importances_):  ## using the attribute provided\n",
    "    feat_dict[name] = score\n",
    "\n",
    "## Features are keys, Importance is the value\n",
    "keys_forest = feat_dict.keys()\n",
    "values_forest = feat_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ee47c55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## to DF and then plotting\n",
    "df_feat_import_forest = pd.DataFrame({'Features': keys_forest, 'Scores': values_forest})\n",
    "df_feat_import_forest = df_feat_import_forest.sort_values(by='Scores', ascending=False)\n",
    "\n",
    "## plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(y=df_feat_import_forest['Features'], width=df_feat_import_forest['Scores'])\n",
    "plt.title('Featutre Importance for RandomForest Model', fontsize=16, c='k')\n",
    "plt.xlabel('Scores', fontsize=16, c='k')\n",
    "plt.ylabel('Features', fontsize=16, c='k')\n",
    "plt.xticks(c='k', fontsize=12)\n",
    "plt.yticks(c='k', fontsize=12)\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65573ea1",
   "metadata": {},
   "source": [
    "### `Boosting`\n",
    "* > `The general idea of most boosting methods is to train predictors \"sequentially\", each trying to correct its predecessor. `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d647019",
   "metadata": {},
   "source": [
    "### `Adaboost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e660741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
       "                   learning_rate=0.5, n_estimators=100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using adaboost for DT as the base estimator\n",
    "adaboost_clf = AdaBoostClassifier(\n",
    "                                    base_estimator=DecisionTreeClassifier(criterion='gini', max_depth=3), \n",
    "                                    n_estimators=100, \n",
    "                                    algorithm='SAMME.R', \n",
    "                                    learning_rate=0.5\n",
    "                                  )\n",
    "adaboost_clf.fit(X_train, y_train)  ## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "291204cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Mean) scores using \"Adaboost\" -- 0.933\n"
     ]
    }
   ],
   "source": [
    "## Using cross validation for prediction and evaluation\n",
    "acc_scores_adaboost = cross_val_score(estimator=adaboost_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "print(f'Accuracy (Mean) scores using \"Adaboost\" -- {acc_scores_adaboost.mean():.3f}', )\n",
    "\n",
    "## Prediction using cross validation\n",
    "y_pred_adaboost = cross_val_predict(estimator=adaboost_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc78955a",
   "metadata": {},
   "source": [
    "### `Gradient Bossting`\n",
    "* > `A simpler way to train GB ensembles is to use Scikit-Learns GradientBoostingRegressor class,  Much like the RandomForestRegressor class, it has hyperparameters to control the growth of Decision Trees, The same is done for classification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f6791c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The learning_rate hyperparameter scales the contribution of each tree. If you set it to a low value, such as 0.1 ..\n",
    "## you will need more trees in the ensemble to fit the training set, but the predictions will usually generalize better\n",
    "## learning_rate works as (Regularization technique called 'shrinkage')\n",
    "gradBoost_clf = GradientBoostingClassifier(n_estimators=150, max_depth=3, learning_rate=0.1)\n",
    "gradBoost_clf.fit(X_train, y_train)  ## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18268000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Mean) scores using \"GradientBoosting\" -- 0.940\n"
     ]
    }
   ],
   "source": [
    "## Using cross validation for prediction and evaluation\n",
    "acc_scores_gradBoost = cross_val_score(estimator=gradBoost_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "print(f'Accuracy (Mean) scores using \"GradientBoosting\" -- {acc_scores_gradBoost.mean():.3f}', )\n",
    "\n",
    "## Prediction using cross validation\n",
    "y_pred_gradBoost = cross_val_predict(estimator=gradBoost_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fccd7a",
   "metadata": {},
   "source": [
    "### `XGBoost`\n",
    "* > `If I will train one model and tune one model and I don't have time to think a lot, of course I will choose it`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4a77c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=500, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## XGBoost is an API, not an algorithm, it is the implementation of Gradient Boosting, but much faster and strong\n",
    "## I recommend you to know much more about xgboost --> it is very powerfull API\n",
    "\n",
    "## objective --> 'multi:softproba' ---> for multiclassification\n",
    "## objective --> 'binary:logistic' ---> for binaryclassification\n",
    "\n",
    "## Here I tried to put some Hyperparams\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softprob',   ## The most one according to your task (here, Multiclass class.)\n",
    "                            learning_rate=0.01,           ## eta or learning_rate \n",
    "                            n_estimators=500,             ## number of trees\n",
    "                            use_label_encoder=False,)     ## only to remove the warning\n",
    "xgb_clf.fit(X_train, y_train)  ## train, deal with it as an ordinary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61e386c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Mean) scores using \"XGBoost\" -- 0.947\n"
     ]
    }
   ],
   "source": [
    "## Using cross validation for prediction and evaluation\n",
    "acc_scores_xgboost = cross_val_score(estimator=xgb_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "print(f'Accuracy (Mean) scores using \"XGBoost\" -- {acc_scores_xgboost.mean():.3f}', )\n",
    "\n",
    "## Prediction using cross validation\n",
    "y_pred_xgboost = cross_val_predict(estimator=xgb_clf, X=X_train, y=y_train, cv=5, n_jobs=-1, method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc958af1",
   "metadata": {},
   "source": [
    "### `Done`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
